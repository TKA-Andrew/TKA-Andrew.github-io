<div class="flexContainer">    
    <div fxLayout="column" fxLayoutGap="10px">
        <h1>Localization Notes</h1>
        <div>
            <h2>Introduction</h2>
            <ul>
                <li>Localization is about determining the robot's pose in a mapped environment.</li>
                <li>Probabilistic algorithms are normally used to track or estimate a robot's position and orientation.</li>
                <li>There are 4 popular Localization algorithms:</li>
                    <ul>
                        <li>Extended Kalman Filter</li>
                        <li>Markov Localization</li>
                        <li>Grid Localization</li>
                        <li>Monte Carlo Localization</li>
                    </ul>
                <li>There are 3 types of Localization problems:</li>
                    <ul>
                        <li>Position Tracking / Local Localization</li>
                            <ul>
                                <li>The robot knows its initial pose</li>
                                <li>The challenge of this problem is the uncertainty of the environments (for example, 
                                    a robot might experience wheel slip when moving on a carpet)
                                </li>
                            </ul>
                        <li>Global Localization</li>
                            <ul>
                                <li>The robot doesnt know its initial pose</li>
                                <li>The robot needs to determine its pose relative to the ground truth map</li>
                            </ul>
                        <li>Kipnapped Robot</li>
                            <ul>
                                <li>This problem is similar to Global Localization problem, except that
                                    the robot may be kipnapped (moved) to a new position at any time.
                                </li>
                            </ul>
                    </ul>
                <li>There are 2 types of environments need to be considered: static environment and dynamic environment</li>
                <li>Dynamic environment is more difficult to localize in.</li>
            </ul>
            <mat-divider></mat-divider>
        </div>

        <div>
            <h2>Kalman Filter</h2>
            <h3>Introduction to Kalman Filter</h3>
            <ul>
                <li>Kalman Filter is a very prominent estimation algorithm that is used to estimate the value of a variable
                    in real-time as the data is being collected.
                </li>
                <li>Advantages of Kalman Filter algorithm:</li>
                    <ul>
                        <li>can provide a very accurate estimate of the real value</li>
                        <li>can quickly perform the estimation with just a few sensor measurements</li>
                        <li>can consider sensor fusion to provide a more accurate estimation</li>
                    </ul>
                <li>Kalman Filter algorithm is an iteration of 2 steps, prior with an initial estimate:</li>
                    <ul>
                        <li>State Prediction</li>
                        <li>Measurement Update</li>
                    </ul>
                <li>Even with an awful initial guess (as long as the mean is logical and not too over), the Kalman Filter algorithm
                    will still be able to estimate the state very quickly and accurately.</li>
                <li>There are few types of Kalman Filters:</li>
                    <ul>
                        <li>KF - linear</li>
                        <li>Extended KF - nonlinear</li>
                        <li><a href="http://ais.informatik.uni-freiburg.de/teaching/ws12/mapping/pdf/slam05-ukf.pdf" target="_blank" rel="noopener noreferrer">Unscented KF</a> - highly nonlinear</li>
                    </ul>
                <li>The basis of Kalman Filter is the Gaussian Distribution.</li>
            </ul>

            <h3>1D Kalman Filter</h3>
            <h4>1D Gaussian</h4>
            <ul>
                <li>Formula: <div class="matheqn" [mathjax]="'$$p(x) = \\frac {1}{\\sigma\\sqrt{2\\pi}} e^{-\\frac{(x-\\mu)^2}{2\\sigma^2}}$$'"></div>
                   
                
                    where:
                    <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$\\mu\\text{ : mean}$'"></div>
                    <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$\\sigma\\text{ : standard deviation}$'"></div>
                    <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$\\sigma^2\\text{ : variance}$'"></div>
                </li>
                <li>Code: </li>
                    <pre>
                        <code>
double gaussian1D(double mu, double sigma, double x)
&#123;
    double prob = 1.0 / (sigma * sqrt(2.0 * M_PI)) * exp(-0.5 * pow((x - mu), 2.0) / pow(sigma, 2.0));
    return prob;
}
                        </code>
                    </pre>
            </ul>

            <h4>Naming Conventions</h4>
            <ul>
                <li><div class="matheqn-small" [mathjax]="'$x_t\\text{ : state}$'"></div></li>
                <li><div class="matheqn-small" [mathjax]="'$z_t\\text{ : measurement}$'"></div></li>
                <li><div class="matheqn-small" [mathjax]="'$u_t\\text{ : control action}$'"></div></li>
            </ul>
            <h4>Measurement Update</h4>
            <ul>
                <li>In the first iteration of the algorithm, our initial guess (which is also a gaussian distribution with mean and variance) will become our prior belief.</li>
                <li>Then, we will get a measurement (which is also a gaussian distribution with mean and variance).</li>
                <li>With this 2 gaussian distrbutions, we can estimate the posterior belief by getting the new mean and new variance:
                    <div class="matheqn" [mathjax]="'$$\\mu_{new} = \\frac {r^2\\mu + \\sigma^2v}{r^2 + \\sigma^2}$$'"></div>
                    <div class="matheqn" [mathjax]="'$${\\sigma^2}_{new} = \\frac {1}{\\frac {1}{r^2} + \\frac {1}{\\sigma^2}}$$'"></div>
                    where:
                    <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$\\mu\\text{ : mean of prior belief}$'"></div>
                    <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$\\sigma^2\\text{ : variance of prior belief}$'"></div>
                    <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$v\\text{ : mean of measurement}$'"></div>
                    <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$r^2\\text{ : variance of measurement}$'"></div>
                </li>
            </ul>

            <h4>State prediction</h4>
            <ul>
                <li>Now, the new mean and new variance that we calculated in the Measurement Update process are now referrerd to as the prior belief.</li>
                <li>State prediction is the estimation that takes place after an inevitably uncertain motion.</li>
                <li>The motion is also a gaussian distribution with a mean and variance.</li>
                <li>To get the next gaussian distribution (which represents the state), simply sum up the mean and variance from both prior belief
                    and motion:
                    <div class="matheqn" [mathjax]="'$$\\mu_{new} = \\mu_1 + \\mu_2$$'"></div>
                    <div class="matheqn" [mathjax]="'$${\\sigma^2}_{new} = {\\sigma^2}_{1} + {\\sigma^2}_{2}$$'"></div>
                </li>
            </ul>

            <h4>Implementation of 1D Kalman Filter</h4>
            <ul>
                <li>You might ask how to get the mean and variance for the measurements and motions in actual. 
                    Well, actually we can assume the measurement we get is the mean, and we can set the variance
                    by ourselves accordingly.
                </li>
                <li>Code example:
                    <pre>
                        <code>
    #include &lt;iostream>
    #include &lt;math.h>
    #include &lt;tuple>
    
    using namespace std;
    
    double new_mean, new_var;
    
    tuple&lt;double, double> measurement_update(double mean1, double var1, double mean2, double var2)
    &#123;
        new_mean = (var2 * mean1 + var1 * mean2) / (var1 + var2);
        new_var = 1 / (1 / var1 + 1 / var2);
        return make_tuple(new_mean, new_var);
    }
    
    tuple&lt;double, double> state_prediction(double mean1, double var1, double mean2, double var2)
    &#123;
        new_mean = mean1 + mean2;
        new_var = var1 + var2;
        return make_tuple(new_mean, new_var);
    }
    
    int main()
    &#123;
        //Measurements and measurement variance
        double measurements[5] = &#123; 5, 6, 7, 9, 10 };
        double measurement_sig = 4;
        
        //Motions and motion variance   m,ean
        double motion[5] = &#123; 1, 1, 2, 1, 1 };
        double motion_sig = 2;
        
        //Initial state
        double mu = 0;
        double sig = 1000;
    
        for (int i = 0; i &lt; sizeof(measurements) / sizeof(measurements[0]); i++) &#123;
            tie(mu, sig) = measurement_update(mu, sig, measurements[i], measurement_sig);
            printf("update:  [%f, %f]\n", mu, sig);
            tie(mu, sig) = state_prediction(mu, sig, motion[i], motion_sig);
            printf("predict: [%f, %f]\n", mu, sig);
        }
    
        return 0;
    }                                
                        </code>
                    </pre>
                </li>
            </ul>
        </div>
        
        <div>
            <h3>Multi-Dimensional Kalman Filter</h3>
            <h4>Multivariate Gaussian</h4>
            <ul>
                <li>Multivariate Gaussian can be 2D, 3D, 4D etc. Depending on how many dimensions or variables there are, the mean and 
                    covariance will have different size. The following are the mean and covariance of 2D Gaussians.
                </li>
                <li>Mean</li>
                    <div class="matheqn" [mathjax]="'$$\\mu = \\begin{bmatrix}
                    \\mu_x \\\\
                    \\mu_y
                    \\end{bmatrix}$$'"></div>
                <li>Covariance</li>
                    <div class="matheqn" [mathjax]="'$$\\Sigma = \\begin{bmatrix}
                    \\sigma_x^2 & \\sigma_x\\sigma_y \\\\
                    \\sigma_y\\sigma_x & \\sigma_y^2
                    \\end{bmatrix}$$'"></div>
                <li>Formula for the multivariate Gaussian</li>
                    <div class="matheqn" [mathjax]="'$$p(x) = \\frac {1}{(2\\pi)^{\\frac{1}{2}}|\\Sigma|^{\\frac{1}{2}}} e^{-\\frac{1}{2} (x-\\mu)^T \\Sigma^{-1} (x-\\mu)}$$'"></div>
            </ul>

            <h4>Kalman Filter Equations</h4>
            <ul>
                <li>State Prediction:</li>
                <ul>
                    <li>Take note that this X is equivalent to the &mu; above</li>
                        <div class="matheqn" [mathjax]="'$$X^{\'} = FX$$'"></div>
                        where:
                        <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$X^{\'}\\text{ : posterior state}$'"></div>
                        <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$\\text{F : state transition function}$'"></div>
                        <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$\\text{X : prior state}$'"></div>
                        <br>The state transition function and state are depending on your application.
                        <br>For example, if the state is about displacement and velocity, and we assume velocity is always constant:
                        <div class="matheqn" [mathjax]="'$$X = \\begin{bmatrix}
                        x_x \\\\
                        \\dot{x}
                        \\end{bmatrix}$$'"></div>
                        <div class="matheqn" [mathjax]="'$$F = \\begin{bmatrix}
                        1 & \\delta t \\\\
                        0 & 1
                        \\end{bmatrix}$$'"></div>
                    <li>To calculate the posterior covariance, the prior covariance P is multiplied by F squared, and added Q as process noise</li>
                        <div class="matheqn" [mathjax]="'$$P^{\'} = FPF^{T} + Q$$'"></div>
                        where:
                        <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$P^{\'}\\text{ : posterior covariance}$'"></div>
                        <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$FF^{T}\\text{ : }F^2$'"></div>
                        <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$\\text{P : prior covariance}$'"></div>
                        <div class="matheqn-small" style="margin-left: 40px;" [mathjax]="'$\\text{Q : process noise}$'"></div>
                </ul>

                <li>Measurement Update</li>
                <ul>
                    <li>Symbol z is used to represent the matrix of measurement.</li>
                    <li>There is a measurement function, called H, which demonstrates how to map state(x) to observation(z).</li>
                    <li>For example, let's say the state X is about displacement and velocity, but our measurement is only measuring displacement, then
                        the measurement function is:
                        <div class="matheqn" [mathjax]="'$$H = \\begin{bmatrix}
                        1 \\ 
                        0
                        \\end{bmatrix}$$'"></div>
                    </li>
                    <li>The measurement residual (difference between measurement and expected measurement) also need to be calculated:</li>
                    <div class="matheqn" [mathjax]="'$$y = z - HX^{\'}$$'"></div>
                    <li>There is also another equation S, which considers measurement noise (R) and will be used in calculating Kalman Gain later:</li>
                    <div class="matheqn" [mathjax]="'$$S = HP^{\'}H^T+R$$'"></div>
                </ul>

                <li>Calculation of Kalman Gain</li>
                <ul>
                    <li><div class="matheqn" [mathjax]="'$$K = P^{\'}H^TS^{-1}$$'"></div></li>
                </ul>

                <li>To further calculate posterior state and posterior covariance</li>
                <ul>
                    <li><div class="matheqn" [mathjax]="'$$X = X^{\'}+Ky$$'"></div></li>
                    <li><div class="matheqn" [mathjax]="'$$P = (I - KH)P^{\'}$$'"></div></li>
                </ul>
            </ul>
        </div>

        <div>
            <h3>Extended Kalman Filter</h3>
            <h4>Introduction</h4>
            <ul>
                <li>When using Kalman Filter, there are 2 assumptions made:</li>
                    <ul>
                        <li>Motion and measurement models are linear</li>
                        <li>State space can be represented by a unimodal Gaussian Distribution</li>
                    </ul>
                <li>The Kalman Filter cannot be used when the measurement and/or state transition functions are nonlinear, since this would result in a non-Gaussian distribution.</li>
                <li>For example, if let's say we are tracking the x and y coordinates of a robot, our state will be:
                    <div class="matheqn" [mathjax]="'$$X = \\begin{bmatrix}
                    x \\\\
                    y
                    \\end{bmatrix}$$'"></div>
                    and let's say our sensor only measures the distance from the robot to the object, r, as well as the angle between r and the x-axis, θ, our measurement will be:
                    <div class="matheqn" [mathjax]="'$$Z = \\begin{bmatrix}
                    r \\\\
                    \\theta
                    \\end{bmatrix}$$'"></div>
                    Unlike the previous example that shows linear state transition function between displacement and velocity, we can't compute a linear F for this.
                    <br>The measurement function is also no longer linear because:
                    <div class="matheqn" [mathjax]="'$$r = \\sqrt{x^2 + y^2}$$'"></div>
                    <div class="matheqn" [mathjax]="'$$\\theta = tan^{-1}\\frac{y}{x}$$'"></div>
                </li>
                
            </ul>
            <mat-divider></mat-divider>
        </div>
        
        <div>
            <h2>Monte Carlo Localization</h2>
            <h3>Introduction</h3>
            <ul>
                <li>Monte Carlo Localization (MCL) can only solve Local and Global localization problems, it cannot solve kipnapped robot problem.</li>
                <li>As compared to EKF, MCL has some advantages:</li>
                    <ul>
                        <li>Easier to implement/code</li>
                        <li>Can handle global localization problem (EKF can only handle local localization problem</li>
                        <li>MCL is not limited to Gaussian Distribution</li>
                    </ul>
                <li>MCL uses particles to localize the robot.</li>
                <li>The algorithm of MCL:</li>
                    <ul>
                        <li>Randomly and uniformly place N numbers of particles on the map.</li>
                        <li>Each particle has four private members: x, y, theta, weight</li>
                        <li>There will be few landmarks on the map, which will be later used to estimate the position of the particles and robot.</li>
                        <li>When the robot moves, for example, rotate clockwise 90 degreen and move forward 2m, the same action should be
                            updated on all particles.
                        </li>
                        <li>Get robot's measurements (z), which are the distances of the robot from the landmarks.</li>
                        <li>Update weight of each particle depending on the robot's measurement z and also the particle's position.</li>
                        <li>Resample the particles with a sample probability proportional to the importance weight</li>
                        <li>Repeat</li>
                    </ul>
            </ul>
            <mat-divider></mat-divider>
        </div>
    </div>
</div>